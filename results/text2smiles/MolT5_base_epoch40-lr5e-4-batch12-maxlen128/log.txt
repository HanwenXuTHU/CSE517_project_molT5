2023-03-08 08:45:49,464 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 08:45:49,465 - __main__ - INFO - Epoch: 0, Loss: 1.6270267963409424, Best Loss: 0.6228051411284914
2023-03-08 09:04:34,440 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 09:04:34,441 - __main__ - INFO - Epoch: 1, Loss: 1.0928505659103394, Best Loss: 0.4726554268728133
2023-03-08 09:22:54,259 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 09:22:54,260 - __main__ - INFO - Epoch: 2, Loss: 0.9723274111747742, Best Loss: 0.3657674376947294
2023-03-08 09:40:32,592 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 09:40:32,593 - __main__ - INFO - Epoch: 3, Loss: 0.9157602190971375, Best Loss: 0.31373457643000974
2023-03-08 09:57:38,048 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 09:57:38,049 - __main__ - INFO - Epoch: 4, Loss: 0.8300389647483826, Best Loss: 0.25654865315426933
2023-03-08 10:14:26,488 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 10:14:26,491 - __main__ - INFO - Epoch: 5, Loss: 0.8115639090538025, Best Loss: 0.22249529918358796
2023-03-08 10:30:48,891 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 10:30:48,892 - __main__ - INFO - Epoch: 6, Loss: 0.6234356760978699, Best Loss: 0.19403336523775597
2023-03-08 10:46:49,786 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 10:46:49,786 - __main__ - INFO - Epoch: 7, Loss: 0.4980563223361969, Best Loss: 0.16914290197841506
2023-03-08 11:02:43,536 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 11:02:43,540 - __main__ - INFO - Epoch: 8, Loss: 0.42082393169403076, Best Loss: 0.14755817060021392
2023-03-08 11:18:26,370 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 11:18:26,373 - __main__ - INFO - Epoch: 9, Loss: 0.3212001919746399, Best Loss: 0.13225185150361574
2023-03-08 11:34:14,464 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 11:34:14,470 - __main__ - INFO - Epoch: 10, Loss: 0.23368540406227112, Best Loss: 0.12217727420932578
2023-03-08 11:50:02,328 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 11:50:02,340 - __main__ - INFO - Epoch: 11, Loss: 0.2051810324192047, Best Loss: 0.1138116063388146
2023-03-08 12:05:46,264 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 12:05:46,268 - __main__ - INFO - Epoch: 12, Loss: 0.13817603886127472, Best Loss: 0.1061468933155572
2023-03-08 12:21:39,349 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 12:21:39,355 - __main__ - INFO - Epoch: 13, Loss: 0.10951860249042511, Best Loss: 0.10416047237273571
2023-03-08 12:37:21,861 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 12:37:21,862 - __main__ - INFO - Epoch: 14, Loss: 0.16005097329616547, Best Loss: 0.10006429637660795
2023-03-08 12:53:05,921 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 12:53:05,925 - __main__ - INFO - Epoch: 15, Loss: 0.12634600698947906, Best Loss: 0.09830767423778342
2023-03-08 13:08:52,966 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 13:08:52,976 - __main__ - INFO - Epoch: 16, Loss: 0.08536264300346375, Best Loss: 0.09699298064831807
2023-03-08 13:24:40,382 - __main__ - INFO - save model to ./results/text2smiles/MolT5_base_epoch40-lr5e-4-batch12-maxlen128/model_best.pt
2023-03-08 13:24:40,388 - __main__ - INFO - Epoch: 17, Loss: 0.05653339996933937, Best Loss: 0.095604664295156
